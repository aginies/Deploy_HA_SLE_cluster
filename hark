#!/usr/bin/python3
import sys
import os
import time
import argparse
from contextlib import contextmanager
from configparser import SafeConfigParser
from io import StringIO
import subprocess
import requests
from lxml import etree

LOG_FILE = "hark.log"
LOG_ENABLED = True
DEBUG = False
QUIET = False
NONINTERACTIVE = False
OFFLINE = False # Offline mode
DOWNLOAD = False  # Download isos if they aren't available locally


def memoize(function):
    "Decorator to invoke a function once only for any argument"
    memoized = {}

    def inner(*args):
        if args in memoized:
            return memoized[args]
        r = function(*args)
        memoized[args] = r
        return r
    return inner


def die(*args):
    """
    Broken out as special case for log() failure.  Ordinarily you
    should just use error() to terminate.
    """
    if DEBUG:
        import pdb
        pdb.set_trace()
    raise ValueError(" ".join([str(arg) for arg in args]))


def error(*args):
    log("ERROR: {}".format(" ".join([str(arg) for arg in args])))
    die(*args)


def warn(*args):
    log("WARNING: {}".format(" ".join([str(arg) for arg in args])))
    print(" ".join([str(arg) for arg in args]))


def log(*args):
    if not LOG_ENABLED:
        return
    try:
        with open(LOG_FILE, "a") as logfile:
            logfile.write(" ".join([str(arg) for arg in args]) + "\n")
    except IOError:
        die("Can't append to {} - aborting".format(LOG_FILE))


def ask(msg):
    "Ask for user confirmation"
    msg += ' '
    if msg.endswith('? '):
        msg = msg[:-2] + ' (y/n)? '

    if NONINTERACTIVE:
        log("? {} [Y]".format(msg))
        return True

    while True:
        try:
            ans = input(msg)
        except EOFError:
            ans = 'n'
        if ans:
            ans = ans[0].lower()
            if ans in 'yn':
                log('? {} [{}]'.format(msg, ans.upper()))
                return ans == 'y'


def log_start():
    """
    Convenient side-effect: this will die immediately if the log file
    is not writable (e.g. if not running as root)
    """
    datestr = get_stdout("date --rfc-3339=seconds")[1].decode('utf-8')
    log('================================================================')
    log("{} {}".format(datestr, " ".join(sys.argv)))
    log('----------------------------------------------------------------')


def getuser():
    "Returns the name of the current user"
    import getpass
    return getpass.getuser()


def gethostname():
    return os.uname()[1]


def get_stdout(cmd, input_s=None, stderr_on=True, shell=True):
    '''
    Run a cmd, return stdout output.
    Optional input string "input_s".
    stderr_on controls whether to show output which comes on stderr.
    '''
    if stderr_on:
        stderr = None
    else:
        stderr = subprocess.PIPE
    proc = subprocess.Popen(cmd,
                            shell=shell,
                            stdin=subprocess.PIPE,
                            stdout=subprocess.PIPE,
                            stderr=stderr)
    stdout_data, stderr_data = proc.communicate(input_s)
    return proc.returncode, stdout_data.strip()


def get_stdout_stderr(cmd, input_s=None, shell=True):
    '''
    Run a cmd, return (rc, stdout, stderr)
    '''
    proc = subprocess.Popen(cmd,
                            shell=shell,
                            stdin=input_s and subprocess.PIPE or None,
                            stdout=subprocess.PIPE,
                            stderr=subprocess.PIPE)
    stdout_data, stderr_data = proc.communicate(input_s)
    return proc.returncode, stdout_data.strip(), stderr_data.strip()


def invoke(*args, **kwargs):
    """
    Log command execution to log file.
    Log output from command to log file.
    Return returncode == 0
    Optional argument: echo_stdout, echo_stderr (default False)
    """
    log("+ " + " ".join(args))
    rc, stdout, stderr = get_stdout_stderr(" ".join(args))
    if stdout:
        stdout = stdout.decode('utf-8')
        log(stdout)
        if kwargs.get("echo_stdout"):
            print(stdout)
    if stderr:
        stderr = stderr.decode('utf-8')
        log(stderr)
        if kwargs.get("echo_stderr"):
            print(stderr, file=sys.stderr)
    return rc == 0


def status(msg):
    log("# " + msg)
    if not QUIET:
        print("  {}".format(msg))


def status_long(msg):
    log("# {}...".format(msg))
    if not QUIET:
        sys.stdout.write("  {}...".format(msg))
        sys.stdout.flush()


def status_progress():
    if not QUIET:
        sys.stdout.write(".")
        sys.stdout.flush()


def status_done():
    log("# done")
    if not QUIET:
        print("done")


@contextmanager
def create_tempfile(suffix='', dir=None):
    """ Context for temporary file.

    Will find a free temporary filename upon entering
    and will try to delete the file on leaving, even in case of an exception.

    Parameters
    ----------
    suffix : string
        optional file suffix
    dir : string
        optional directory to save temporary file in

    (from http://stackoverflow.com/a/29491523)
    """
    import tempfile
    tf = tempfile.NamedTemporaryFile(delete=False, suffix=suffix, dir=dir)
    tf.file.close()
    try:
        yield tf.name
    finally:
        try:
            os.remove(tf.name)
        except OSError as e:
            if e.errno == 2:
                pass
            else:
                raise


@contextmanager
def open_atomic(filepath, mode="r", buffering=-1, fsync=False):
    """ Open temporary file object that atomically moves to destination upon
    exiting.

    Allows reading and writing to and from the same filename.

    The file will not be moved to destination in case of an exception.

    Parameters
    ----------
    filepath : string
        the file path to be opened
    fsync : bool
        whether to force write the file to disk

    (from http://stackoverflow.com/a/29491523)
    """

    with create_tempfile(dir=os.path.dirname(os.path.abspath(filepath))) as tmppath:
        with open(tmppath, mode, buffering) as file:
            try:
                yield file
            finally:
                if fsync:
                    file.flush()
                    os.fsync(file.fileno())
        os.rename(tmppath, filepath)


def str2file(s, fname):
    '''
    Write a string to a file.
    '''
    try:
        with open_atomic(fname, 'w') as dst:
            dst.write(s)
    except IOError as msg:
        error(msg)
        return False
    return True


def mksalt():
    import string
    from random import choice
    _saltchars = string.ascii_letters + string.digits + './'
    return '$6$' + ''.join(choice(_saltchars) for _ in range(16))


def crypt_passwd(passwd):
    import crypt
    return crypt.crypt(passwd, mksalt())


@memoize
def get_variants(baseurl):
    r = requests.get(baseurl)
    if r.status_code == 200:
        parser = etree.HTMLParser()
        tree = etree.parse(StringIO(r.text), parser)

        def filter_path(p):
            if not p.startswith('SLE-') and not p.startswith('openSUSE-'):
                return False
            if any(p.endswith('{}/'.format(x)) for x in ('BACKUP', 'Ports', 'UNTESTED', '.old')):
                return False
            if not p.endswith('/'):
                return False
            return True
        return [p[:-1] for p in tree.xpath('//a/@href') if filter_path(p)]
    raise ValueError("Failed to get {}: Status code {}".format(baseurl, r.status_code))


@memoize
def get_isos(baseurl, variant):
    r = requests.get("{}/{}/".format(baseurl, variant))
    if r.status_code == 200:
        parser = etree.HTMLParser()
        tree = etree.parse(StringIO(r.text), parser)

        def filter_path(p):
            return ".iso" in p
        return [p for p in tree.xpath('//a/@href') if filter_path(p)]

    raise ValueError("Failed to get {}/{}/: Status code {}".format(baseurl, variant, r.status_code))


class Section(object):
    def __init__(self, items, name=None):
        if name is not None:
            self.__dict__["name"] = name
        self.__dict__.update(items)

    def __repr__(self):
        return str(self.__dict__)


class Config(object):
    def __init__(self, fns, root=None):
        cfg = SafeConfigParser()
        cfg.read(fns)

        for section in cfg.sections():
            if ':' in section:
                lst, name = section.split(':', 1)
                if not hasattr(self, lst):
                    setattr(self, lst, [])
                if lst == "vm":
                    getattr(self, lst).append(Section(cfg.items("common") + cfg.items(section), name=name))
                else:
                    getattr(self, lst).append(Section(cfg.items(section), name=name))
            else:
                setattr(self, section, Section(cfg.items(section)))

        def resolve_section(s, env):
            for k, v in s.__dict__.items():
                s.__dict__[k] = v.format(**env)

        def mkenv(s):
            env = {}
            if root:
                env["config"] = root
            for k, v in s.__dict__.items():
                env[k] = v
            return env

        lists = []
        for section in cfg.sections():
            if ':' in section:
                lst, name = section.split(':', 1)
                if getattr(self, lst) not in lists:
                    lists.append(getattr(self, lst))
            else:
                s = getattr(self, section)
                resolve_section(s, mkenv(s))
        for l in lists:
            for s in l:
                resolve_section(s, mkenv(s))

    def __repr__(self):
        return str(self.__dict__)

    def __str__(self):
        import json

        class MyEncoder(json.JSONEncoder):
            def default(self, o):
                return o.__dict__
        return json.dumps(config, sort_keys=True, indent=2, cls=MyEncoder)


def mkconfigenv(cfg):
    env = {}
    for k, v in cfg.__dict__.items():
        env[k] = v
    return env


def mkdirp(d, mode=0o777):
    if os.path.isdir(d):
        return True
    os.makedirs(d, mode=mode)


def mkconfig():
    config = Config(['hark.ini', os.path.expanduser('~/.hark.ini')])
    if config.iso.url.endswith('/'):
        config.iso.url = config.iso.url[:-1]
    if not os.path.isdir(config.iso.path):
        mkdirp(config.iso.path)
    config.user.password = crypt_passwd(config.user.password)
    return config


downloads = {}


def start_download(url, outname):
    if outname in downloads:
        return
    cmd = ["curl", "-s", "-S", "--fail", "-o", outname, url]
    log("+ {}".format(" ".join(cmd)))
    proc = subprocess.Popen(cmd)
    downloads[outname] = proc


def wait_for_downloads():
    if len(downloads):
        status_long("Waiting for {} downloads to complete".format(len(downloads)))
    while True:
        done = {}
        for outname, dl in downloads.items():
            if dl.poll() is not None:
                done[outname] = dl
        for outname, dl in done.items():
            status_done()
            status("Done: {} (rc = {})".format(outname, dl.returncode))
            del downloads[outname]
            if len(downloads):
                status_long("Waiting for {} downloads to complete".format(len(downloads)))
        if len(downloads) == 0:
            return
        time.sleep(2)
        status_progress()


def cmd_iso(args):
    if args.variant is None:
        baseurl = config.iso.url
        variants = get_variants(baseurl)
        print("\n".join(variants))
        return

    if args.iso is None:
        if args.variant == "iso":
            global DOWNLOAD
            DOWNLOAD = True
            check_isos()
            wait_for_downloads()
            check_iso_sha1sums()
            return

        baseurl = config.iso.url
        isos = get_isos(baseurl, args.variant)
        print('\n'.join(isos))
        return

    baseurl = config.iso.url
    variant = args.variant
    iso = args.iso

    if os.path.isfile(os.path.join(config.iso.path, iso)):
        error("{} already exists in {}".format(iso, config.iso.path))

    url = '{}/{}/{}'.format(baseurl, variant, iso)
    start_download(url, os.path.join(config.iso.path, iso))


def config_scenario(scenario):
    """
    Load and add scenario to configuration
    """
    if scenario is None:
        error("Scenario is required")
    if not os.path.isfile(scenario):
        options = ("scenarios/{}.ini".format(scenario), "/usr/share/hark/scenarios/{}.ini".format(scenario))
        if os.path.isfile(options[0]):
            scenario = options[0]
        elif os.path.isfile(options[1]):
            scenario = options[1]
        else:
            error("Unknown scenario: {}".format(scenario))

    config.scenario = Config([scenario], root=config)


def install_virtualization_stack():
    if "ID=opensuse" in open("/etc/os-release").read():
        status_long("Install virtualization stack for openSUSE")
        if config.host.hypervisor == "kvm":
            packages = "patterns-openSUSE-kvm_server"
        else:
            packages = "xen_server xen-tools"
        if not invoke("zypper -q -n install -y {}".format(packages)):
            error("Failed to install hypervisor")
    else:
        status("Install virtualization stack for SLES")
        if not invoke("zypper -q -n install -y patterns-sles-{0}_server patterns-sles-{0}_tools".format(config.host.hypervisor)):
            error("Failed to install hypervisor")
    if not invoke("systemctl restart libvirtd"):
        error("Failed to restart libvirtd")
    status_done()


def replace_in_block(fname, newtext, opener="# *** Generated by hark + ***", closer="# *** Generated by hark - ***"):
    if not os.path.exists(fname):
        with open(fname, "w") as f:
            f.write("{}\n{}{}\n".format(opener, newtext, closer))
        return True
    text = open(fname).read()
    if newtext in text:
        return False
    with open_atomic(fname, "w") as f:
        state = 0
        for line in text.splitlines():
            if state == 0:
                f.write(line)
                f.write('\n')
                if line == opener:
                    state = 1
                    f.write(newtext)
            elif state == 1:
                if line == closer:
                    f.write(line)
                    f.write('\n')
                    state = 2
            elif state == 2:
                f.write(line)
                f.write('\n')
        if state == 0:
            f.write(opener)
            f.write('\n')
            f.write(newtext)
        if state <= 1:
            f.write(closer)
            f.write('\n')
    return True


def prepare_etc_hosts():
    """
    Ensure /etc/hosts points to the right nodes
    Only edit within "our" block in /etc/hosts
    """
    status("Prepare /etc/hosts")
    if replace_in_block("/etc/hosts",
                        "".join("{}  {} {}\n".format(vm.address, vm.fqdn, vm.name) for vm in config.scenario.vm)):
        os.chmod("/etc/hosts", 0o644)


def prepare_virtual_network():
    """
    Define HAnet private HA network (NAT)
    NETWORK will be ${NETWORK}.0/24 gw/dns ${NETWORK}.1
    """
    path = "/etc/libvirt/qemu/networks/{}.xml".format(config.network.name)
    hosts = ""
    for vm in config.scenario.vm:
        hosts += '        <host mac="{mac}" name="{fqdn}" ip="{address}" />\n'.format(**vm.__dict__)
    status_long("Prepare virtual network ({})".format(path))
    str2file("""<network>
  <name>{name}</name>
  <uuid>{uuid}</uuid>
  <forward mode='nat'/>
  <bridge name='{interface}' stp='on' delay='0'/>
  <mac address='{hostmac}'/>
  <domain name='{name}'/>
  <ip address='{range}.1' netmask='255.255.255.0'>
    <dhcp>
      <range start='{range}.128' end='{range}.254'/>
{hosts}
    </dhcp>
  </ip>
</network>
""".format(hosts=hosts, **mkconfigenv(config.network)), path)
    os.chmod(path, 0o644)
    status_progress()
    invoke("systemctl restart libvirtd")
    status_progress()
    invoke("virsh net-autostart {}".format(config.network.name))
    status_progress()
    invoke("virsh net-start {}".format(config.network.name))
    status_done()


def create_tempdir():
    from tempfile import mkdtemp
    return mkdtemp(dir="/tmp", prefix="hark-")


def ssh_root_key():
    keypath = "/root/.ssh/{}".format(config.user.sshkey)
    if not os.path.exists(keypath):
        status("Generate ~/.ssh/{} without password".format(config.user.sshkey))
        invoke('ssh-keygen', '-t', 'rsa', '-f', '~/.ssh/{}'.format(config.user.sshkey), '-N', '""')

    vms = " ".join(vm.name for vm in config.scenario.vm)
    newconfig = "Host {}\nIdentityFile /root/.ssh/{}\n".format(vms, config.user.sshkey)
    if replace_in_block("/root/.ssh/config", newconfig):
        status("Updated /root/.ssh/config")


def destroy_shared_pool():
    sharedpool = config.storage.sharedpool
    log("Destroy current pool {}".format(sharedpool))
    invoke("virsh", "pool-destroy", sharedpool)
    log("Undefine current pool {}".format(sharedpool))
    invoke("virsh", "pool-undefine", sharedpool)

def prepare_shared_pool():
    """
    Create an shared volume pool on the host
    """
    status_long("Prepare and create shard pool and volume")
    _, outp = get_stdout("virsh pool-list --all")
    outp = outp.decode('utf-8')
    sharedpool = config.storage.sharedpool
    if sharedpool in outp:
        status_progress()
        destroy_shared_pool()
    shareddisk = config.storage.shareddisk
    if os.path.isfile(shareddisk):
        os.remove(shareddisk)
    status_progress()
    log("Define pool {}".format(sharedpool))
    mkdirp(os.path.join(config.storage.path, sharedpool))
    invoke("virsh", "pool-define-as", "--name", sharedpool, "--type", "dir", "--target", os.path.join(config.storage.path, sharedpool))
    status_progress()
    log("Start and Autostart the pool")
    invoke("virsh", "pool-start", sharedpool)
    invoke("virsh", "pool-autostart", sharedpool)
    status_progress()
    log("Create the shared volume")

    def sized(s):
        s = s.lower()
        if s.endswith('g'):
            return int(s[:-1]) * 1024 * 1024 * 1024
        if s.endswith('m'):
            return int(s[:-1]) * 1024 * 1024
        if s.endswith('k'):
            return int(s[:-1]) * 1024
        return int(s)

    diskname = os.path.basename(config.storage.shareddisk)

    doc = """<volume>
  <name>{name}</name>
  <capacity>{capacity}</capacity>
  <allocation>{capacity}</allocation>
  <shareable/>
  <target>
    <format type='raw'/>
  </target>
</volume>
""".format(name=diskname, capacity=sized(config.storage.sharedsize))

    with create_tempfile() as tmppath:
        with open(tmppath, "w") as f:
            f.write(doc)
        invoke("virsh", "vol-create", "--pool", sharedpool, "--file", tmppath)
    status_done()


def generate_vm_template(exedir, outputdir):
    if os.path.isfile("{}/templates/vm.xml".format(exedir)):
        t_path = "{}/templates".format(exedir)
    else:
        t_path = "/usr/share/hark/templates"

    t_vm = open("{}/vm.xml".format(t_path)).read()
    t_addon = open("{}/addon.xml".format(t_path)).read()
    t_package = open("{}/package.xml".format(t_path)).read()
    t_hosts_entry = open("{}/hosts_entry.xml".format(t_path)).read()

    for vm in config.scenario.vm:
        addons = "".join(t_addon.format(name=a.name, dev="/dev/sr{}".format(i)) for i, a in enumerate(a for a in config.scenario.addon if a.name != "base"))
        packages = "".join(t_package.format(name=pkg) for pkg in vm.packages.split())
        hosts = "".join(t_hosts_entry.format(**vm.__dict__) for vm in config.scenario.vm)
        txt = t_vm.format(
            addons=addons,
            packages=packages,
            hosts=hosts,
            keymap=vm.keymap,
            networkname=config.network.name,
            timezone=vm.timezone,
            username=config.user.name,
            userpass=config.user.password
        )
        fn = os.path.join(outputdir, "{}.xml".format(vm.name))
        str2file(txt, fn)
        os.chmod(fn, 0o644)


def prepare_auto_deploy_image():
    """
    Create a RAW file which contains auto install file for deployment
    """
    status("Prepare the Autoyast image for VM guest installation")
    tmpmount = create_tempdir()
    wdir = create_tempdir()
    cwd = os.getcwd()
    os.chdir(config.storage.path)
    try:
        generate_vm_template(cwd, wdir)
        diskname = os.path.basename(config.scenario.common.autoyastdisk)
        invoke("qemu-img create {} -f raw 2M".format(diskname))
        invoke("mkfs.ext3 {}".format(diskname))
        invoke("mount {} {}".format(diskname, tmpmount))
        invoke("mkdir {}/ssh".format(tmpmount))
        invoke("cp -v {0}/*.xml {1}".format(wdir, tmpmount))
        invoke("cp -v /root/.ssh/{0} {1}/ssh/id_rsa".format(config.user.sshkey, tmpmount))
        invoke("cp -v /root/.ssh/{0}.pub {1}/ssh/id_rsa.pub".format(config.user.sshkey, tmpmount))
        invoke("cp -v /root/.ssh/{0}.pub {1}/ssh/authorized_keys".format(config.user.sshkey, tmpmount))
        invoke("cp -v /root/.ssh/{0}.pub {1}/ssh/known_keys".format(config.user.sshkey, tmpmount))
        invoke("umount {}".format(tmpmount))
    finally:
        invoke("rm -rf {} {}".format(tmpmount, wdir))
        os.chdir(cwd)


def cmd_hostcfg(args):
    """
    Configure the host:
    * Install virtualization tools and restart libvirtd
    * Generate a SSH root key, and prepare a config to connect to HA nodes
    # no need for this, we can handle this part
    * Add HA nodes in /etc/hosts
    * Create a virtual network: DHCP with host/mac/name/ip for HA nodes
    * Create an shared volume pool
    * Prepare an image (raw) containing autoyast file
    """
    if getuser() != "root":
        error("Command has to run as root.")
    ssh_root_key()
    install_virtualization_stack()
    prepare_etc_hosts()
    prepare_virtual_network()
    prepare_shared_pool()
    prepare_auto_deploy_image()


def resolve_iso_file(addon):
    import fnmatch
    varianturl, isofile = addon.iso.rsplit('/', 1)
    baseurl, variant = varianturl.rsplit('/', 1)

    if OFFLINE:
        for f in os.listdir(config.iso.path):
            if fnmatch.fnmatch(f, isofile):
                return f
    else:
        isos = get_isos(baseurl, variant)
        for iso in isos:
            if fnmatch.fnmatch(iso, isofile):
                return iso
    error("Found no ISO matching {} at {}".format(isofile, varianturl))


def check_isos():
    for addon in config.scenario.addon:
        isofile = resolve_iso_file(addon)
        if not os.path.isfile(os.path.join(config.iso.path, isofile)):
            if OFFLINE:
                error("Missing ISO: {}".format(isofile))
            isourl = addon.iso.rsplit('/', 1)[0] + '/' + isofile
            if not DOWNLOAD:
                error("Missing ISO: {}".format(isourl))
            status("Downloading missing ISO: {}".format(isourl))
            start_download(isourl, os.path.join(config.iso.path, isofile))


def check_iso_sha1sums():
    if OFFLINE:
        return
    status_long("Download SHA1 checksums")
    sha1sumurls = set()
    sums = {}
    for addon in config.scenario.addon:
        sha1sumurl = addon.iso.rsplit('/', 1)[0] + '/SHA1SUMS'
        sha1sumurls.add(sha1sumurl)
    for url in sha1sumurls:
        r = requests.get(url)
        if r.status_code == 200:
            for l in r.text.splitlines():
                checksum, filename = l.split()
                sums[filename] = checksum
    status_done()
    for addon in config.scenario.addon:
        fname = resolve_iso_file(addon)
        fpath = os.path.join(config.iso.path, fname)
        if not os.path.isfile(fpath):
            error("File not found: {}".format(fpath))
        if fname in sums:
            status_long("Verify {}".format(fname))
            import hashlib
            m = hashlib.sha1()
            with open(fpath, 'rb') as f:
                while True:
                    block = f.read(2**10)  # Magic number: one-megabyte blocks.
                    if not block:
                        break
                    m.update(block)
            if m.hexdigest() != sums[fname]:
                error("SHA1 sum not matching for {}: {} != {}".format(fname, m.hexdigest(), sums[fname]))
            status_done()
        else:
            status("No checksum for {}, skipping".format(fname))


def cleanup_vm():
    pooldir = os.path.join(config.storage.path, config.storage.vmpool)
    if os.path.isdir(pooldir):
        images = [f for f in os.listdir(pooldir) if f.endswith(".qcow2")]
        if len(images) > 0:
            status("WARNING! This will remove previous HA VM guest images in {}!".format(pooldir))
            status("Images: {}".format(" ".join(images)))
            if not ask("Remove images?"):
                return
    _, vmlist = get_stdout("virsh -q list --all")
    vmlist = vmlist.decode('utf-8')

    for vm in config.scenario.vm:
        name = "{}{}".format(vm.distro, vm.name)
        if name in vmlist.split():
            status("Delete VM {}".format(name))
            invoke("virsh destroy {}".format(name))
            invoke("virsh undefine {}".format(name))
            invoke("virsh vol-delete --pool {} {}.qcow2".format(config.storage.vmpool, name))


def check_before_install():
    status("Check disks before install")
    for disk in (config.scenario.common.autoyastdisk,
                 config.storage.shareddisk):
        if not os.path.isfile(disk):
            error("{} not found, needed for autoinstallation".format(disk))


def destroy_pool(poolname):
    path = os.path.join(config.storage.path, poolname)
    invoke("virsh pool-destroy {}".format(poolname))
    invoke("virsh pool-undefine {}".format(poolname))
    invoke("rm -rvf {}".format(path))


def create_pool(poolname):
    "Create a pool (on host)"
    status("Create pool {}".format(poolname))
    path = os.path.join(config.storage.path, poolname)
    _, outp = get_stdout("virsh -q pool-list --all")
    outp = outp.decode('utf-8')
    if poolname in [l.split()[0] for l in outp.split('\n') if l.strip()]:
        status("{} already present, deleting it".format(poolname))
        destroy_pool(poolname)
    mkdirp(path)
    invoke("virsh pool-define-as --name {} --type dir --target {}".format(poolname, path))
    invoke("virsh pool-start {}".format(poolname))
    invoke("virsh pool-autostart {}".format(poolname))


def install_vms():
    pool = config.storage.vmpool
    for vm in config.scenario.vm:
        vmname = "{}{}".format(vm.distro, vm.name)
        status("Install VM {}".format(vm.name))
        invoke("virsh pool-refresh {}".format(pool))
        invoke("virsh vol-create-as --pool {pool} --name {vmname}.qcow2 --capacity {size} --allocation {size} --format qcow2".format(
            pool=pool, vmname=vmname, size=vm.imagesize))
        invoke("virsh pool-refresh {}".format(pool))

        vmdisk = "{}/{}/{}.qcow2".format(config.storage.path, config.storage.vmpool, vmname)
        autoyastdisk = config.scenario.common.autoyastdisk
        shareddisk = config.storage.shareddisk

        if not os.path.isfile(vmdisk):
            error("{} not present".format(vmdisk))

        cmd = ['screen -d -m -L -S "install_HA_VM_guest_', vmname, '" ',
               'virt-install --name ', vmname,
               ' --ram ', vm.ram,
               ' --vcpus ', vm.vcpu,
               ' --virt-type ', config.host.hypervisor,
               ' --graphics ', 'vnc,keymap=', config.user.keymap,
               ' --network network=', config.network.name, ',mac=', vm.mac,
               ' --disk path=', vmdisk, ',format=qcow2,bus=virtio,cache=none',
               ' --disk path=', shareddisk, ',format=raw,bus=virtio,cache=none',
               ' --disk path=', autoyastdisk, ',format=raw,bus=virtio']

        baseloc = None
        for addon in config.scenario.addon:
            diskpath = os.path.join(config.iso.path, resolve_iso_file(addon))
            cmd.append(' --disk path={},device=cdrom'.format(diskpath))
            if addon.name == "base":
                baseloc = diskpath

        cmd.extend([' --location ', baseloc,
                    ' --boot cdrom',
                    ' --extra-args autoyast=device://vdc/{}.xml'.format(vm.name),
                    ' --watchdog i6300esb,action=poweroff'
                    ' --console pty,target_type=virtio',
                    ' --check all=off'])
        invoke("".join(cmd))
        # stagger these a bit to try to avoid race (?)
        time.sleep(1)


def cmd_deploy(args):
    """
    Install all nodes with needed data
    * Clean up all previous data: VM definition, VM images
    * Create a hapool to store VM images
    * Install all VMs using screen
    * Display information on how to copy host root key to HA nodes (VM)
    """
    if getuser() != "root":
        error("Command has to run as root.")
    check_isos()
    cleanup_vm()
    create_pool(config.storage.vmpool)
    wait_for_downloads()
    check_iso_sha1sums()
    check_before_install()
    install_vms()


def determine_status():
    if not os.path.exists("/usr/bin/virsh"):
        return 'unknown'
    rc, outp = get_stdout("virsh -q list --all")
    if rc != 0:
        warn("Failed to list virtual machines")
        return 'unknown'
    for line in outp.decode('utf-8').splitlines():
        if config.scenario.common.distro in line:
            if 'running' in line:
                return 'running'
            if 'shut off' in line:
                return 'created'
    return 'unknown'


def cmd_up(args):
    """
    Configures the host (if necessary) and deploys the VMs
    (again, if necessary)
    """
    _, outp = get_stdout("screen -list")
    if 'install_HA_VM_guest_' in outp.decode('utf-8'):
        error("Installations in progress!")

    state = determine_status()
    if state == 'created':
        for vm in config.scenario.vm:
            vmname = "{}{}".format(vm.distro, vm.name)
            invoke("virsh start {}".format(vmname))
    elif state == 'running':
        status("Already running")
    else:
        cmd_hostcfg(args)
        cmd_deploy(args)

    if args.bootstrap:
        wait_to_bootstrap()

        class Bootstrapargs():
            pass
        bargs = Bootstrapargs()
        bargs.nodes = None
        cmd_bootstrap(bargs)
    elif args.wait:
        wait_to_bootstrap()


def wait_to_bootstrap():
    status_long("Wait for nodes to start")
    nodes = [vm.name for vm in config.scenario.vm]
    while True:
        state = determine_status()
        if state == 'running':
            break
        time.sleep(5)
        status_progress()
    status_done()
    status_long("Wait for nodes to appear on network")
    while True:
        rc, outp = get_stdout("virsh -q net-dhcp-leases {}".format(config.network.name))
        outp = outp.decode('utf-8')
        if rc == 0:
            if all(node in outp for node in nodes):
                break
        time.sleep(5)
        status_progress()
    status_done()
    status_long("Try to connect")
    while True:
        if all(do_remote(n, "true", stderr_on=False) for n in nodes):
            break
        time.sleep(5)
        status_progress()
    status_done()


def cmd_halt(args):
    """
    Tell running vms to halt
    """
    _, outp = get_stdout("screen -list")
    if 'install_HA_VM_guest_' in outp.decode('utf-8'):
        if not ask("Installations in progress! Do you really want to tell VMs to halt?"):
            return

    rc, outp = get_stdout("virsh -q list --all")
    if rc != 0:
        error("Failed to list virtual machines")

    for line in outp.decode('utf-8').splitlines():
        if config.scenario.common.distro in line:
            vmname = line.split()[1]
            if "running" not in line:
                status("{} not running".format(vmname))
                continue
            if not invoke("virsh -q destroy {} --graceful".format(vmname)):
                warn("Failed to halt {}".format(vmname))


def cmd_status(args):
    """
    Displays status of configuration (is host configured?
    Are VMs created? Are VMs running?
    Is there a cluster running on the VMs?)
    """

    print("# Networks:")
    nnetworks = 0
    rc, outp = get_stdout("virsh -q net-list")
    if rc != 0:
        error("Failed to list networks")
    for line in outp.decode('utf-8').splitlines():
        if config.network.name in line:
            nnetworks += 1
            print("  ", line.strip())

    # get IP addresses
    if nnetworks > 0:
        print("")
        rc, outp = get_stdout("virsh -q net-dhcp-leases {}".format(config.network.name))
        if rc != 0:
            error("Failed to list IP addresses for {}".format(config.network.name))
        for line in outp.decode('utf-8').splitlines():
            if line.strip():
                print("  ", line.strip())

    print("\n# Pools:")
    rc, outp = get_stdout("virsh -q pool-list")
    if rc != 0:
        error("Failed to list pools")
    pools = []
    for line in outp.decode('utf-8').splitlines():
        if config.storage.vmpool in line:
            pools.append(config.storage.vmpool)
            print("  ", line.strip())
        elif config.storage.sharedpool in line:
            pools.append(config.storage.sharedpool)
            print("  ", line.strip())
    print("\n# Volumes:")
    for pool in pools:
        rc, outp = get_stdout("virsh -q vol-list {}".format(pool))
        if rc == 0:
            for line in outp.decode('utf-8').splitlines():
                if config.storage.path in line:
                    print("  ", line.strip())

    # check vms
    print("\n# Virtual machines:")
    running = False
    rc, outp = get_stdout("virsh -q list --all")
    if rc != 0:
        error("Failed to list virtual machines")
    for line in outp.decode('utf-8').splitlines():
        if config.scenario.common.distro in line:
            if "running" in line:
                running = True
            print("  ", line.strip())

    # list installations in progress
    print("\n# Installations in progress:")
    rc, outp = get_stdout("screen -list")
    # Ignore rc == 1 since it just means there are no screens to list
    no_installations = True
    if rc == 0:
        for line in outp.decode('utf-8').splitlines():
            if 'install_HA_VM_guest_' in line:
                no_installations = False
                print("  ", line.strip())

    has_crmmon = hasattr(args, "crmmon") and args.crmmon
    if has_crmmon and running and no_installations:
        rc, outp = get_stdout("ssh -q -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no root@{} crm_mon -D1jr".format(args.crmmon))
        if rc == 0:
            print("\n# Cluster status:")
            print(outp.decode('utf-8'))


def cmd_checkiso(args):
    check_iso_sha1sums()


def cmd_destroy(args):
    """
    Stop and remove VMs

    TODO: clean up properly

    vol-list <pool>
    vol-delete --pool <pool> <vol>

    pool-list --all
    pool-destroy hashared
    pool-delete hashared
    pool-undefine hashared

    net-list --all
    if active:
    net-destroy HAnet
    if existing:
    net-undefine HAnet
    """
    if getuser() != "root":
        error("Command has to run as root.")
    cleanup_vm()

    if args.all:

        def virsh(cmds, tgt):
            for cmd in cmds.split():
                invoke("virsh -q {} {}".format(cmd, tgt))

        if invoke("virsh -q pool-info {}".format(config.storage.vmpool)):
            status("Delete pool {}".format(config.storage.vmpool))
            virsh('pool-destroy pool-delete pool-undefine', config.storage.vmpool)

        if invoke("virsh -q pool-info {}".format(config.storage.sharedpool)):
            status("Delete pool {}".format(config.storage.sharedpool))
            invoke("virsh vol-delete --pool {} {}".format(config.storage.sharedpool, os.path.basename(config.storage.shareddisk)))
            virsh('pool-destroy pool-delete pool-undefine', config.storage.sharedpool)

        if invoke("virsh -q net-uuid {}".format(config.network.name)):
            status("Delete network {}".format(config.network.name))
            virsh('net-destroy net-undefine', config.network.name)


def cmd_config(args):
    print(config)


def pssh(*args, nodes=None):
    if nodes is None:
        nodes = " ".join(vm.name for vm in config.scenario.vm)
    return invoke(
        'pssh -H "{nodes}" -l root -p 30 -t 0 -x "-o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no" "{cmd}"'.format(
            nodes=nodes, cmd=" ".join(args)))


def pscp(src, dst, nodes=None):
    if nodes is None:
        nodes = " ".join(vm.name for vm in config.scenario.vm)
    return invoke(
        'pscp -H "{nodes}" -r -l root -p 30 -t 0 -x "-o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no" "{src}" "{dst}"'.format(
            nodes=nodes, src=src, dst=dst))


def do_remote(node, cmd, stderr_on=True):
    return invoke("ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no root@{} {}".format(node, cmd),
                  stderr_on=stderr_on)


def cmd_bootstrap(args):
    """
    Bootstrap cluster on configured nodes
    """
    if getuser() != "root":
        error("Command has to run as root.")

    if args.nodes is None:
        nodelist = [vm.name for vm in config.scenario.vm]
    else:
        nodelist = args.nodes.split()

    status("Check status of cluster nodes")
    for n in nodelist:
        if do_remote(n, "systemctl -q is-active corosync.service", stderr_on=False):
            error("Cluster already active on {}".format(n))

    status_long("Initialize cluster")
    if not do_remote(nodelist[0], "ha-cluster-init -y -t ocfs2 -p /dev/vdb"):
        error("Failed to initialize cluster")
    status_done()
    if len(nodelist) > 1:
        if len(nodelist) > 2:
            status("Adjust OCFS2 configuration for > 2 nodes")
            if not do_remote(nodelist[0], "crm resource meta c-clusterfs show clone-max 2>/dev/null") and \
               not do_remote(nodelist[0], "crm resource meta c-clusterfs set clone-max 2"):
                error("Failed to update cluster configuration")
        status_long("Join cluster from remaining nodes")
        for n in nodelist[1:]:
            if not do_remote(n, "ha-cluster-join -y -c {}".format(nodelist[0])):
                error("Failed to join cluster ({}) from {}".format(nodelist[0], n))
            status_progress()
        status_done()


def cmd_run(args):
    """
    Run command on nodes (default: all nodes)
    """
    if args.once:
        nodelist = [config.scenario.vm[0].name]
    elif args.nodes is None:
        nodelist = [vm.name for vm in config.scenario.vm]
    else:
        nodelist = args.nodes.split()

    cmd = args.cmd.replace('"', "\\\"")
    nodes = " ".join(nodelist)
    invoke(
        'pssh -H "{nodes}" -l root -p 30 -t 0 -x "-o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no" "{cmd}"'.format(
            nodes=nodes, cmd=cmd))


def cmd_ssh(args):
    """
    SSH to node
    TODO: don't put SSH key in /root, no need for that.. can just
    keep key in .hark/ and ssh via hark
    """
    if not os.path.isdir('.hark'):
        mkdirp('.hark')
    addr = args.node
    for vm in config.scenario.vm:
        if vm.name == args.node:
            addr = vm.address
    cmd = ['ssh',
           '-o', 'UserKnownHostsFile=.hark/known_hosts',
           '-o', 'StrictHostKeyChecking=no',
           '-o', 'IdentityFile=/root/.ssh/{}'.format(config.user.sshkey),
           'root@{}'.format(addr)]
    if args.cmd is not None:
        cmd.append(args.cmd)
    subprocess.call(cmd)


def cmd_test(args):
    """
    TODO: point to test script from scenario file
    pass identity details and node list to test script?
    """
    pass

config = None


def main():
    global config
    global QUIET
    global LOG_ENABLED
    global DEBUG
    global NONINTERACTIVE
    global DOWNLOAD
    global OFFLINE
    try:
        parser = argparse.ArgumentParser(description='''Hark! A tool for setting up a test cluster for SLE HA.
        Configure your scenarios using the hark.ini and scenario files.
        Run 'up' to prepare the host and create virtual machines,
        run 'status' to see the state of the cluster, and once
        installation completes, run 'bootstrap' to configure the
        cluster.''')

        parser.add_argument('-q', '--quiet', help="Minimal output", action="store_true")
        parser.add_argument('-Q', '--no-log', dest="nolog", help="Disable log", action="store_true")
        parser.add_argument('-n', '--non-interactive', dest="noninteractive", help="Assume yes to all prompts", action="store_true")
        parser.add_argument('-x', '--debug', help="Halt in debugger on error", action="store_true")
        parser.add_argument('-d', '--download', help="Download missing ISO files automatically", action="store_true")
        parser.add_argument('-s', '--scenario', dest="scenario", metavar="SCENARIO", help="Cluster scenario")
        parser.add_argument('--offline', dest="offline", action="store_true", help="Don't connect to ISO server")

        subparsers = parser.add_subparsers()

        subparser = subparsers.add_parser('download', help='List available variants and download ISO files for variants')
        subparser.add_argument('variant', help="Name of variant", nargs='?')
        subparser.add_argument('iso', help="ISO file name", nargs='?')
        subparser.set_defaults(func=cmd_iso)

        subparser = subparsers.add_parser('checkiso', help='Check ISO SHA1SUMS (if available on server)')
        subparser.set_defaults(func=cmd_checkiso)

        subparser = subparsers.add_parser('config', help="Display resolved configuration values")
        subparser.set_defaults(func=cmd_config)

        subparser = subparsers.add_parser('status', help="Display status of configuration")
        subparser.add_argument('-c', '--crmmon', dest="crmmon", help="If set, try to run crm_mon on given node/ip")
        subparser.set_defaults(func=cmd_status)

        subparser = subparsers.add_parser('up', help="Configure the host and bring virtual machines up")
        subparser.add_argument('--wait', dest="wait", action="store_true", help="Wait until VMs are ready")
        subparser.add_argument('--bootstrap', dest="bootstrap", action="store_true", help="Bootstrap HA cluster (unless already bootstrapped)")
        subparser.set_defaults(func=cmd_up)

        subparser = subparsers.add_parser('halt', help="Tell running VMs to halt")
        subparser.set_defaults(func=cmd_halt)

        subparser = subparsers.add_parser('destroy', help="Halt and destroy any created VMs")
        subparser.add_argument('-a', '--all', dest="all", action="store_true", help="Also destroy pools and network")
        subparser.set_defaults(func=cmd_destroy)

        subparser = subparsers.add_parser('bootstrap', help="Bootstrap initial cluster")
        subparser.add_argument('-n', '--nodes', dest="nodes", help="List of nodes to bootstrap cluster on")
        subparser.set_defaults(func=cmd_bootstrap)

        subparser = subparsers.add_parser('test', help="Run cluster test")
        subparser.add_argument('test', help="Test case to run", nargs='?')
        subparser.set_defaults(func=cmd_test)

        subparser = subparsers.add_parser('run', help="Run command on listed nodes")
        subparser.add_argument('-n', '--nodes', dest="nodes", help="List of nodes to bootstrap cluster on")
        subparser.add_argument('--once', dest="once", action="store_true", help="Run command on one node (ignore node list)")
        subparser.add_argument('cmd', help="Command to run")
        subparser.set_defaults(func=cmd_run)

        subparser = subparsers.add_parser('ssh', help="SSH to given node")
        subparser.add_argument('node', help="Node to connect to")
        subparser.add_argument('cmd', help="Command to run", nargs='?')
        subparser.set_defaults(func=cmd_ssh)

        args = parser.parse_args()
        LOG_ENABLED = not args.nolog
        DEBUG = args.debug
        NONINTERACTIVE = args.noninteractive
        QUIET = args.quiet
        DOWNLOAD = args.download
        OFFLINE = args.offline

        log_start()
        config = mkconfig()

        if args.scenario is None:
            config_scenario(config.scenario.default)
        else:
            config_scenario(args.scenario)

        if hasattr(args, "func"):
            args.func(args)
            wait_for_downloads()
        else:
            parser.print_help()
            sys.exit(1)
    except ValueError as e:
        if DEBUG:
            import traceback
            traceback.print_exc()
            import pdb
            pdb.set_trace()
        sys.stderr.write("ERROR: ")
        sys.stderr.write(str(e))
        sys.stderr.write('\n')
        sys.exit(1)
    except Exception as e:
        if DEBUG:
            raise e
        sys.stderr.write("ERROR: ")
        sys.stderr.write(str(e))
        sys.stderr.write('\n')
        sys.exit(1)

if __name__ == "__main__":
    main()
