#!/usr/bin/python
import sys
import os
import time
import argparse
from contextlib import contextmanager
from ConfigParser import SafeConfigParser
from StringIO import StringIO
import subprocess
import requests
from lxml import etree

LOG_FILE = "sleha-deploy.log"
DEBUG = False
QUIET = False
DOWNLOAD = False  # Download isos if they aren't available locally


def memoize(function):
    "Decorator to invoke a function once only for any argument"
    memoized = {}

    def inner(*args):
        if args in memoized:
            return memoized[args]
        r = function(*args)
        memoized[args] = r
        return r
    return inner


def die(*args):
    """
    Broken out as special case for log() failure.  Ordinarily you
    should just use error() to terminate.
    """
    if DEBUG:
        import pdb
        pdb.set_trace()
    raise ValueError(" ".join([str(arg) for arg in args]))


def error(*args):
    log("ERROR: {}".format(" ".join([str(arg) for arg in args])))
    die(*args)


def warn(*args):
    log("WARNING: {}".format(" ".join([str(arg) for arg in args])))
    print " ".join([str(arg) for arg in args])


def log(*args):
    try:
        with open(LOG_FILE, "a") as logfile:
            logfile.write(" ".join([str(arg) for arg in args]) + "\n")
    except IOError:
        die("Can't append to {} - aborting".format(LOG_FILE))


def log_start():
    """
    Convenient side-effect: this will die immediately if the log file
    is not writable (e.g. if not running as root)
    """
    datestr = get_stdout("date --rfc-3339=seconds")[1]
    log('================================================================')
    log("{} {}".format(datestr, " ".join(sys.argv)))
    log('----------------------------------------------------------------')


def getuser():
    "Returns the name of the current user"
    import getpass
    return getpass.getuser()


def gethostname():
    return os.uname()[1]


def get_stdout(cmd, input_s=None, stderr_on=True, shell=True):
    '''
    Run a cmd, return stdout output.
    Optional input string "input_s".
    stderr_on controls whether to show output which comes on stderr.
    '''
    if stderr_on:
        stderr = None
    else:
        stderr = subprocess.PIPE
    proc = subprocess.Popen(cmd,
                            shell=shell,
                            stdin=subprocess.PIPE,
                            stdout=subprocess.PIPE,
                            stderr=stderr)
    stdout_data, stderr_data = proc.communicate(input_s)
    return proc.returncode, stdout_data.strip()


def get_stdout_stderr(cmd, input_s=None, shell=True):
    '''
    Run a cmd, return (rc, stdout, stderr)
    '''
    proc = subprocess.Popen(cmd,
                            shell=shell,
                            stdin=input_s and subprocess.PIPE or None,
                            stdout=subprocess.PIPE,
                            stderr=subprocess.PIPE)
    stdout_data, stderr_data = proc.communicate(input_s)
    return proc.returncode, stdout_data.strip(), stderr_data.strip()


def invoke(*args, **kwargs):
    """
    Log command execution to log file.
    Log output from command to log file.
    Return returncode == 0
    Optional argument: echo_stdout, echo_stderr (default False)
    """
    log("+ " + " ".join(args))
    rc, stdout, stderr = get_stdout_stderr(" ".join(args))
    if stdout:
        log(stdout)
        if kwargs.get("echo_stdout"):
            print stdout
    if stderr:
        log(stderr)
        if kwargs.get("echo_stderr"):
            print >>sys.stderr, stderr
    return rc == 0


def status(msg):
    log("# " + msg)
    if not QUIET:
        print "  {}".format(msg)


def status_long(msg):
    log("# {}...".format(msg))
    if not QUIET:
        sys.stdout.write("  {}...".format(msg))
        sys.stdout.flush()


def status_progress():
    if not QUIET:
        sys.stdout.write(".")
        sys.stdout.flush()


def status_done():
    log("# done")
    if not QUIET:
        print "done"


@contextmanager
def create_tempfile(suffix='', dir=None):
    """ Context for temporary file.

    Will find a free temporary filename upon entering
    and will try to delete the file on leaving, even in case of an exception.

    Parameters
    ----------
    suffix : string
        optional file suffix
    dir : string
        optional directory to save temporary file in

    (from http://stackoverflow.com/a/29491523)
    """
    import tempfile
    tf = tempfile.NamedTemporaryFile(delete=False, suffix=suffix, dir=dir)
    tf.file.close()
    try:
        yield tf.name
    finally:
        try:
            os.remove(tf.name)
        except OSError as e:
            if e.errno == 2:
                pass
            else:
                raise


@contextmanager
def open_atomic(filepath, mode="r", buffering=-1, fsync=False):
    """ Open temporary file object that atomically moves to destination upon
    exiting.

    Allows reading and writing to and from the same filename.

    The file will not be moved to destination in case of an exception.

    Parameters
    ----------
    filepath : string
        the file path to be opened
    fsync : bool
        whether to force write the file to disk

    (from http://stackoverflow.com/a/29491523)
    """

    with create_tempfile(dir=os.path.dirname(os.path.abspath(filepath))) as tmppath:
        with open(tmppath, mode, buffering) as file:
            try:
                yield file
            finally:
                if fsync:
                    file.flush()
                    os.fsync(file.fileno())
        os.rename(tmppath, filepath)


def str2file(s, fname):
    '''
    Write a string to a file.
    '''
    try:
        with open_atomic(fname, 'w') as dst:
            dst.write(s)
    except IOError, msg:
        common_err(msg)
        return False
    return True


def mksalt():
    import string
    from random import choice
    _saltchars = string.ascii_letters + string.digits + './'
    return '$6$' + ''.join(choice(_saltchars) for _ in range(16))


def crypt_passwd(passwd):
    import crypt
    return crypt.crypt(passwd, mksalt())


@memoize
def get_variants(baseurl):
    r = requests.get(baseurl)
    if r.status_code == 200:
        parser = etree.HTMLParser()
        tree = etree.parse(StringIO(r.text), parser)

        def filter_path(p):
            if not p.startswith('SLE-') and not p.startswith('openSUSE-'):
                return False
            if any(p.endswith('{}/'.format(x)) for x in ('BACKUP', 'Ports', 'UNTESTED', '.old')):
                return False
            if not p.endswith('/'):
                return False
            return True
        return [p[:-1] for p in tree.xpath('//a/@href') if filter_path(p)]
    raise ValueError("Failed to get {}: Status code {}".format(baseurl, r.status_code))


@memoize
def get_isos(baseurl, variant):
    r = requests.get("{}/{}/".format(baseurl, variant))
    if r.status_code == 200:
        parser = etree.HTMLParser()
        tree = etree.parse(StringIO(r.text), parser)

        def filter_path(p):
            return ".iso" in p
        return [p for p in tree.xpath('//a/@href') if filter_path(p)]

    raise ValueError("Failed to get {}/{}/: Status code {}".format(baseurl, variant, r.status_code))


class Section(object):
    def __init__(self, items, name=None):
        if name is not None:
            self.__dict__["name"] = name
        self.__dict__.update(items)

    def __repr__(self):
        return str(self.__dict__)


class Config(object):
    def __init__(self, fns, root=None):
        cfg = SafeConfigParser()
        cfg.read(fns)
        if root is None:
            self.__dict__["scenario"] = None

        for section in cfg.sections():
            if ':' in section:
                lst, name = section.split(':', 1)
                if not hasattr(self, lst):
                    setattr(self, lst, [])
                getattr(self, lst).append(Section(cfg.items(section), name=name))
            else:
                setattr(self, section, Section(cfg.items(section)))

        def resolve_section(s, env):
            for k, v in s.__dict__.iteritems():
                s.__dict__[k] = v.format(**env)

        def mkenv(s, is_common=False):
            env = {}
            if root:
                env["config"] = root
            if "common" in cfg.sections():
                for k, v in self.common.__dict__.iteritems():
                    env[k] = v
            if not is_common:
                for k, v in s.__dict__.iteritems():
                    env[k] = v
            return env

        if "common" in cfg.sections():
            resolve_section(self.common, mkenv(self.common, is_common=True))

        lists = []
        for section in cfg.sections():
            if ':' in section:
                lst, name = section.split(':', 1)
                if getattr(self, lst) not in lists:
                    lists.append(getattr(self, lst))
            else:
                s = getattr(self, section)
                resolve_section(s, mkenv(s))
        for l in lists:
            for s in l:
                resolve_section(s, mkenv(s))

    def __repr__(self):
        return str(self.__dict__)

    def __str__(self):
        import json

        class MyEncoder(json.JSONEncoder):
            def default(self, o):
                return o.__dict__
        return json.dumps(config, sort_keys=True, indent=2, cls=MyEncoder)


def mkconfigenv(cfg):
    env = {}
    for k, v in cfg.__dict__.iteritems():
        env[k] = v
    return env


def mkdirp(d, mode=0777):
    if os.path.isdir(d):
        return True
    os.makedirs(d, mode=mode)


def mkconfig():
    config = Config(['sleha-deploy.ini', os.path.expanduser('~/.sleha-deploy.ini')])
    if config.iso.url.endswith('/'):
        config.iso.url = config.iso.url[:-1]
    if not os.path.isdir(config.iso.path):
        mkdirp(config.iso.path)
    config.user.password = crypt_passwd(config.user.password)
    return config


log_start()
config = mkconfig()


downloads = {}


def start_download(url, outname):
    if outname in downloads:
        status("Already downloading {}".format(outname))
        return
    status_long("Download: {}".format(url))
    cmd = ["curl", "-s", "-S", "--fail", "-o", outname, url]
    log("+ {}".format(" ".join(cmd)))
    proc = subprocess.Popen(cmd)
    downloads[outname] = proc


def wait_for_downloads():
    while True:
        done = {}
        for _, outname, dl in downloads:
            if dl.poll() is not None:
                done[outname] = dl
        for outname, dl in done.iteritems():
            status_done()
            status("Done: {} (rc = {})".format(outname, dl.returncode))
            del downloads[outname]
        if len(downloads) == 0:
            return
        time.sleep(2)
        status_progress()


def cmd_iso(args):
    if args.variant is None:
        baseurl = config.iso.url
        variants = get_variants(baseurl)
        print "\n".join(variants)
        return

    if args.iso is None:
        baseurl = config.iso.url
        isos = get_isos(baseurl, args.variant)
        print '\n'.join(isos)
        return

    baseurl = config.iso.url
    variant = args.variant
    iso = args.iso

    if os.path.isfile(os.path.join(config.iso.path, iso)):
        error("{} already exists in {}".format(iso, config.iso.path))

    url = '{}/{}/{}'.format(baseurl, variant, iso)
    start_download(url, os.path.join(config.iso.path, iso))


def config_scenario(scenario):
    """
    Load and add scenario to configuration
    """
    if scenario is None:
        error("Scenario is required")
    if not os.path.isfile(scenario):
        scenariof = "scenarios/{}.ini".format(scenario)
        if os.path.isfile(scenariof):
            scenario = scenariof
        else:
            error("Unknown scenario: {} ({})".format(scenario, scenariof))

    config.scenario = Config([scenario], root=config)


def install_virtualization_stack():
    if "ID=opensuse" in open("/etc/os-release").read():
        status("Install virtualization stack for openSUSE")
        if config.vm.hypervisor == "kvm":
            packages = "patterns-openSUSE-kvm_server"
        else:
            packages = "xen_server xen-tools"
        if not invoke("zypper -q -n install -y {}".format(packages)):
            error("Failed to install hypervisor")
    else:
        status("Install virtualization stack for SLES")
        if not invoke("zypper -q -n install -y patterns-sles-{0}_server patterns-sles-{0}_tools".format(config.vm.hypervisor)):
            error("Failed to install hypervisor")
    if not invoke("systemctl restart libvirtd"):
        error("Failed to restart libvirtd")


def replace_in_block(fname, newtext, opener="# *** Generated by sleha-deploy + ***", closer="# *** Generated by sleha-deploy - ***"):
    if not os.path.exists(fname):
        with open(fname, "w") as f:
            f.write("{}\n{}{}\n".format(opener, newtext, closer))
        return True
    hosts = open(fname).read()
    if newtext in hosts:
        return False
    with open_atomic(fname, "w") as f:
        state = 0
        for line in hosts.splitlines():
            if state == 0:
                f.write(line)
                f.write('\n')
                if line == opener:
                    state = 1
                    f.write(newtext)
            elif state == 1:
                if line == closer:
                    f.write(line)
                    f.write('\n')
                    state = 2
            elif state == 2:
                f.write(line)
                f.write('\n')
        if state == 0:
            f.write(opener)
            f.write('\n')
            f.write(newtext)
            f.write(closer)
            f.write('\n')
    return True


def prepare_etc_hosts():
    """
    Ensure /etc/hosts points to the right nodes
    Only edit within "our" block in /etc/hosts
    """
    status("Prepare /etc/hosts")
    if replace_in_block("/etc/hosts",
                        "".join("{}  {} {}\n".format(vm.address, vm.fqdn, vm.name) for vm in config.scenario.vm)):
        os.chmod("/etc/hosts", 0o644)


def prepare_virtual_network():
    """
    Define HAnet private HA network (NAT)
    NETWORK will be ${NETWORK}.0/24 gw/dns ${NETWORK}.1
    TODO: fix hardcoded UUID / MAC / virbr1...
    """
    path = "/etc/libvirt/qemu/networks/{}.xml".format(config.scenario.common.networkname)
    hosts = ""
    for vm in config.scenario.vm:
        hosts += '        <host mac="{mac}" name="{fqdn}" ip="{address}" />\n'.format(**vm.__dict__)
    status("Prepare virtual network ({})".format(path))
    str2file("""<network>
  <name>{networkname}</name>
  <uuid>{networkuuid}</uuid>
  <forward mode='nat'/>
  <bridge name='{networkif} stp='on' delay='0'/>
  <mac address='{networkmac}'/>
  <domain name='{networkname}'/>
  <ip address='{network}.1' netmask='255.255.255.0'>
    <dhcp>
      <range start='{network}.128' end='{network}.254'/>
{hosts}
    </dhcp>
  </ip>
</network>
""".format(hosts=hosts, **mkconfigenv(config.scenario.common)), path)
    os.chmod(path, 0o644)


def create_tempdir():
    from tempfile import mkdtemp
    return mkdtemp(dir="/tmp", prefix="sleha-deploy-")


def ssh_root_key():
    keypath = "/root/.ssh/{}".format(config.user.sshkey)
    if not os.path.exists(keypath):
        status("Generate ~/.ssh/{} without password".format(config.user.sshkey))
        invoke('ssh-keygen', '-t', 'rsa', '-f', '~/.ssh/{}'.format(config.user.sshkey), '-N', '""')

    vms = " ".join(vm.name for vm in config.scenario.vm)
    newconfig = "Host {}\nIdentityFile /root/.ssh/{}\n".format(vms, config.user.sshkey)
    if replace_in_block("/root/.ssh/config", newconfig):
        status("Updated /root/.ssh/config")


def prepare_SBD_pool():
    """
    Create an SBD pool on the host
    """
    status("Prepare SBD pool")
    _, outp = get_stdout("virsh pool-list --all")
    sbdname = config.storage.sbdname
    sbddisk = os.path.join(config.storage.path, config.storage.sbdname, config.storage.sbdname + ".img")
    if sbdname in outp:
        status("Destroy current pool {}".format(sbdname))
        invoke("virsh", "pool-destroy", sbdname)
        status("Undefine current pool {}".format(sbdname))
        invoke("virsh", "pool-undefine", sbdname)
        if os.path.isfile(sbddisk):
            os.remove(sbddisk)
    status("Define pool {}".format(sbdname))
    mkdirp(os.path.join(config.storage.path, sbdname))
    invoke("virsh", "pool-define-as", "--name", sbdname, "--type", "dir", "--target", os.path.join(config.storage.path, sbdname))
    status("Start and Autostart the pool")
    invoke("virsh", "pool-start", sbdname)
    invoke("virsh", "pool-autostart", sbdname)
    status("Create the SBD volume")
    invoke("virsh", "vol-create-as",
           "--pool", sbdname,
           "--name", "{}.img".format(sbdname),
           "--format", "raw",
           "--allocation", "10M",
           "--capacity", "10M")


def generate_vm_template(exedir, outputdir):
    t_vm = open("{}/templates/vm.xml".format(exedir)).read()
    t_addon = open("{}/templates/addon.xml".format(exedir)).read()
    t_package = open("{}/templates/package.xml".format(exedir)).read()
    t_hosts_entry = open("{}/templates/hosts_entry.xml".format(exedir)).read()

    addons = "".join(t_addon.format(**a.__dict__) for a in config.scenario.addon if getattr(a, "base", "no") != "yes")
    packages = "".join(t_package.format(name=pkg) for pkg in config.scenario.common.packages.split())
    hosts = "".join(t_hosts_entry.format(**vm.__dict__) for vm in config.scenario.vm)
    txt = t_vm.format(
        addons=addons,
        packages=packages,
        hosts=hosts,
        keymap=config.vm.keymap,
        networkname=config.scenario.common.networkname,
        timezone=config.vm.timezone,
        username=config.user.name,
        userpass=config.user.password
    )
    str2file(txt, os.path.join(outputdir, config.vm.autoyastfile))
    os.chmod(config.vm.autoyastfile, 0o644)


def prepare_auto_deploy_image():
    """
    Create a RAW file which contains auto install file for deployment
    """
    status("Prepare the Autoyast image for VM guest installation")
    tmpmount = create_tempdir()
    wdir = create_tempdir()
    cwd = os.getcwd()
    os.chdir(config.storage.path)
    try:
        generate_vm_template(cwd, wdir)
        invoke("qemu-img create {} -f raw 2M".format(config.storage.havmdisk))
        invoke("mkfs.ext3 {}".format(config.storage.havmdisk))
        invoke("mount {} {}".format(config.storage.havmdisk, tmpmount))
        invoke("cp -v {}/{} /root/.ssh/{}.pub {}".format(wdir, config.vm.autoyastfile, config.user.sshkey, tmpmount))
        invoke("umount {}".format(tmpmount))
    finally:
        invoke("rm -rf {} {}".format(tmpmount, wdir))
        os.chdir(cwd)


def check_host_config():
    """
    Prints host info
    """
    invoke("virsh net-list", echo_stdout=True)
    invoke("virsh pool-list", echo_stdout=True)
    invoke("virsh vol-list {}".format(config.storage.sbdname), echo_stdout=True)


def cmd_hostcfg(args):
    """
    Configure the host:
    * Install virtualization tools and restart libvirtd
    * Generate a SSH root key, and prepare a config to connect to HA nodes
    # no need for this, we can handle this part
    * Add HA nodes in /etc/hosts
    * Create a virtual network: DHCP with host/mac/name/ip for HA nodes
    * Create an SBD pool
    * Prepare an image (raw) containing autoyast file
    """
    config_scenario(args.scenario)
    ssh_root_key()
    install_virtualization_stack()
    prepare_etc_hosts()
    prepare_virtual_network()
    prepare_SBD_pool()
    prepare_auto_deploy_image()
    check_host_config()


def resolve_iso_file(addon):
    import fnmatch
    varianturl, isofile = addon.iso.rsplit('/', 1)
    baseurl, variant = varianturl.rsplit('/', 1)
    isos = get_isos(baseurl, variant)
    for iso in isos:
        if fnmatch.fnmatch(iso, isofile):
            return iso
    error("Found no ISO matching {} at {}".format(isofile, varianturl))


def check_isos():
    for addon in config.scenario.addon:
        isofile = resolve_iso_file(addon)
        if not os.path.isfile(os.path.join(config.iso.path, isofile)):
            isourl = addon.iso.rsplit('/', 1)[0] + '/' + isofile
            if not DOWNLOAD:
                error("Missing ISO: {}".format(isourl))
            status("Downloading missing ISO: {}".format(isourl))
            start_download(isourl, os.path.join(config.iso.path, isofile))


def cleanup_vm():
    status("Cleanup VM")
    pooldir = os.path.join(config.storage.path, config.vm.libvirtpool)
    if os.path.isdir(pooldir):
        status("WARNING!")
        status("This will remove previous HA VM guest images in {}!".format(pooldir))
        status("Images: {}".format(" ".join(f for f in os.listdir(pooldir) if f.endswith(".qcow2"))))
    _, vmlist = get_stdout("virsh -q list --all")

    for vm in config.scenario.vm:
        name = "{}{}".format(config.vm.distro, vm.name)
        if name in vmlist.split():
            status("Destroy current VM: {}".format(name))
            invoke("virsh destroy {}".format(name))
            status("Undefine current VM: {}".format(name))
            invoke("virsh undefine {}".format(name))
        status("Remove previous image file for VM {0} ({0}.qcow2)".format(name))
        invoke("rm -rvf {}.qcow2".format(os.path.join(config.storage.path, config.vm.libvirtpool, name)))


def check_before_install():
    status("Check disks before install")
    havmdiskpath = os.path.join(config.storage.path, config.storage.havmdisk)
    sbddiskpath = os.path.join(config.storage.path, config.storage.sbdname, "{}.img".format(config.storage.sbdname))
    if not os.path.isfile(havmdiskpath):
        error("{} not found, needed for autoinstallation".format(havmdiskpath))
    if not os.path.isfile(sbddiskpath):
        error("{} not found, needed for autoinstallation".format(sbddiskpath))


def create_pool(poolname):
    "Create a pool (on host)"
    status("Create pool {}".format(poolname))
    path = os.path.join(config.storage.path, poolname)
    _, outp = get_stdout("virsh -q pool-list --all")
    if poolname in [l.split()[0] for l in outp.split('\n') if l.strip()]:
        status("{} already present, deleting it".format(poolname))
        invoke("virsh pool-destroy {}".format(poolname))
        invoke("virsh pool-undefine {}".format(poolname))
        invoke("rm -rvf {}".format(path))
    mkdirp(path)
    invoke("virsh pool-define-as --name {} --type dir --target {}".format(poolname, path))
    invoke("virsh pool-start {}".format(poolname))
    invoke("virsh pool-autostart {}".format(poolname))


def install_vms():
    pool = config.vm.libvirtpool
    for vm in config.scenario.vm:
        vmname = "{}{}".format(config.vm.distro, vm.name)
        status("Install VM {}".format(vm.name))
        invoke("virsh pool-refresh {}".format(pool))
        invoke("virsh vol-create-as --pool {pool} --name {vmname}.qcow2 --capacity {size} --allocation {size} --format qcow2".format(
            pool=pool, vmname=vmname, size=config.vm.imagesize))
        invoke("virsh pool-refresh {}".format(pool))

        vmdisk = "{}/{}/{}.qcow2".format(config.storage.path, config.vm.libvirtpool, vmname)
        havmdiskpath = os.path.join(config.storage.path, config.storage.havmdisk)
        sbddiskpath = os.path.join(config.storage.path, config.storage.sbdname, "{}.img".format(config.storage.sbdname))

        if not os.path.isfile(vmdisk):
            error("{} not present".format(vmdisk))

        cmd = ['screen -d -m -S "install_HA_VM_guest_', vmname, '" ',
               'virt-install --name ', vmname,
               ' --ram ', config.vm.ram,
               ' --vcpus ', config.vm.vcpu,
               ' --virt-type ', config.vm.hypervisor,
               ' --graphics ', 'vnc,keymap=', config.vm.keymap,
               ' --network network=', config.scenario.common.networkname, ',mac=', vm.mac,
               ' --disk path=', vmdisk, ',format=qcow2,bus=virtio,cache=none',
               ' --disk path=', sbddiskpath, ',bus=virtio',
               ' --disk path=', havmdiskpath, ',bus=virtio']

        baseloc = None
        for addon in config.scenario.addon:
            isofile = addon.iso.rsplit('/', 1)[-1]
            diskpath = os.path.join(config.iso.path, isofile)
            cmd.append(' --disk path={},device=cdrom'.format(diskpath))
            if hasattr(addon, "base") and addon.base == "yes":
                baseloc = diskpath

        cmd.extend([' --location ', baseloc,
                    ' --boot cdrom',
                    ' --extra-args ', config.vm.extraargs,
                    ' --watchdog i6300esb,action=poweroff'
                    ' --console pty,target_type=virtio',
                    ' --check all=off'])
        invoke("".join(cmd))


def copy_ssh_key():
    print "- Don't forget to copy the root host SSH key to VM guest"
    for vm in config.scenario.vm:
        print "ssh-copy-id -f -i /root/.ssh/{}.pub -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no {}".format(config.user.sshkey, name)

    print ""
    print "- Clean up your /root/.ssh/known_hosts from previous config (dirty way below)"
    print "rm -vf /root/.ssh/known_hosts"


def cmd_deploy(args):
    """
    Install all nodes with needed data
    * Clean up all previous data: VM definition, VM images
    * Create a hapool to store VM images
    * Install all VMs using screen
    * Display information on how to copy host root key to HA nodes (VM)
    """
    config_scenario(args.scenario)
    check_isos()
    cleanup_vm()
    create_pool(config.vm.libvirtpool)
    wait_for_downloads()
    check_before_install()
    install_vms()
    # check vms
    invoke("virsh list --all", echo_stdout=True)
    # get IP addresses
    invoke("virsh net-dhcp-leases {}".format(config.scenario.common.networkname), echo_stdout=True)
    # list installations in progress
    invoke("screen -list", echo_stdout=True)

    copy_ssh_key()


def cmd_config(args):
    if args.scenario is not None:
        config_scenario(args.scenario)
    print config


def main():
    global QUIET
    global DEBUG
    global DOWNLOAD
    try:
        parser = argparse.ArgumentParser(description='''Tools for setting up a test cluster for SLE HA.
        Configure your scenarios using the sleha-deploy.ini and scenario files,
        run configure-host to prepare SSH keys, libvirt and the hypervisor,
        and then run deploy to create the virtual machines.''')

        parser.add_argument('-q', '--quiet', help="Minimal output", action="store_true")
        parser.add_argument('-x', '--debug', help="Halt in debugger on error", action="store_true")
        parser.add_argument('-d', '--download', help="Download missing ISO files automatically", action="store_true")

        subparsers = parser.add_subparsers()

        parser_iso = subparsers.add_parser('download', help='List available variants and download ISO files for variants'.format(config.iso.url))
        parser_iso.add_argument('variant', help="Name of variant", nargs='?')
        parser_iso.add_argument('iso', help="ISO file name", nargs='?')
        parser_iso.set_defaults(func=cmd_iso)

        parser_hostcfg = subparsers.add_parser('configure-host', help="Configure the host")
        parser_hostcfg.add_argument('scenario', help="Scenario to set up")
        parser_hostcfg.set_defaults(func=cmd_hostcfg)

        parser_deploy = subparsers.add_parser('deploy', help="Install all nodes with needed data")
        parser_deploy.add_argument('scenario', help="Scenario to set up")
        parser_deploy.set_defaults(func=cmd_deploy)

        parser_deploy = subparsers.add_parser('print-configuration', help="Display resolved configuration values")
        parser_deploy.add_argument('scenario', help="Scenario to load", nargs='?')
        parser_deploy.set_defaults(func=cmd_config)

        args = parser.parse_args()
        DEBUG = args.debug
        QUIET = args.quiet
        DOWNLOAD = args.download
        args.func(args)
        wait_for_downloads()
    except Exception as e:
        if DEBUG:
            import traceback
            traceback.print_exc()
            import pdb
            pdb.set_trace()
        sys.stderr.write("ERROR: ")
        sys.stderr.write(str(e))
        sys.stderr.write('\n')
        sys.exit(1)

if __name__ == "__main__":
    main()
